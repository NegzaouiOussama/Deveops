pipeline {
    agent any
    
    tools {
        maven 'Maven3'
    }
    
    environment {
        MAVEN_HOME = "${tool 'Maven3'}"
        PATH = "${env.MAVEN_HOME}/bin:${env.PATH}"
        SONAR_HOST_URL = "http://172.29.114.102:9000"
        SONAR_TOKEN = "sqa_53a643aea3ccdbcedef2c73df0428a1d8397d01e"
        DOCKER_USERNAME = "negzaoui"
        DOCKER_PASSWORD = "dckr_pat_o-R1u9Ij5dpajyvfK7xcH6PRP6w"
        DOCKER_IMAGE_NAME = "student-management"
        DOCKER_IMAGE_TAG = "${env.BUILD_NUMBER}"
    }
    
    stages {
        stage('Checkout') {
            steps {
                git branch: 'main', url: 'https://github.com/NegzaouiOussama/Deveops.git'
            }
        }
        
        stage('Test') {
            steps {
                sh 'mvn clean test'
            }
            post {
                always {
                    junit 'target/surefire-reports/*.xml'
                    // Sauvegarder le fichier jacoco.exec pour le rapport
                    sh 'test -f target/jacoco.exec && echo "JaCoCo execution data saved" || echo "No JaCoCo execution data"'
                }
            }
        }
        
        stage('Generate JaCoCo Report') {
            steps {
                sh 'mvn jacoco:report'
            }
        }
        
        stage('Package') {
            steps {
                sh 'mvn package -DskipTests'
            }
            post {
                success {
                    archiveArtifacts artifacts: 'target/*.jar', fingerprint: true
                }
            }
        }
        
        stage('MVN SONARQUBE') {
            steps {
                script {
                    // V√©rifier d'abord que SonarQube est accessible
                    echo "üîç V√©rification de l'accessibilit√© SonarQube..."
                    def sonarCheck = sh(
                        script: """
                            curl -s -o /dev/null -w "%{http_code}" ${env.SONAR_HOST_URL}/api/system/status || echo "000"
                        """,
                        returnStdout: true
                    ).trim()
                    
                    if (sonarCheck != "200") {
                        echo "‚ö†Ô∏è  ATTENTION: SonarQube pourrait ne pas √™tre accessible (HTTP ${sonarCheck})"
                        echo "   V√©rifiez que SonarQube est d√©marr√©: docker ps | grep sonarqube"
                        echo "   Ou d√©marrez-le: docker start sonarqube"
                        echo "   Le pipeline va quand m√™me essayer de se connecter..."
                    } else {
                        echo "‚úÖ SonarQube est accessible (HTTP ${sonarCheck})"
                    }
                    
                    // Ex√©cuter l'analyse avec timeout augment√© et meilleure gestion d'erreurs
                    echo "üìä D√©marrage de l'analyse SonarQube..."
                    try {
                        timeout(time: 10, unit: 'MINUTES') {
                    sh """
                        mvn sonar:sonar \\
                            -Dsonar.host.url=${env.SONAR_HOST_URL} \\
                            -Dsonar.login=${env.SONAR_TOKEN} \\
                                    -Dsonar.coverage.jacoco.xmlReportPaths=target/site/jacoco/jacoco.xml \\
                                    -Dsonar.qualitygate.wait=false \\
                                    -Dsonar.scanner.force-deprecated-java-version=true
                            """
                        }
                        echo "‚úÖ Analyse SonarQube termin√©e avec succ√®s"
                    } catch (Exception e) {
                        echo "‚ùå Erreur lors de l'analyse SonarQube: ${e.getMessage()}"
                        echo "üìã Diagnostic:"
                        echo "   1. V√©rifiez que SonarQube est accessible: curl ${env.SONAR_HOST_URL}/api/system/status"
                        echo "   2. V√©rifiez que le token est valide"
                        echo "   3. V√©rifiez les logs SonarQube: docker logs sonarqube --tail 50"
                        echo "   4. Le pipeline continue malgr√© l'erreur SonarQube..."
                        // Ne pas faire √©chouer le pipeline √† cause de SonarQube
                        // catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                        //     throw e
                        // }
                    }
                }
            }
            post {
                always {
                    script {
                        echo "üìä SonarQube Analysis Stage Completed"
                        echo "üîó Dashboard: ${env.SONAR_HOST_URL}/dashboard?id=tn.esprit:student-management"
                        echo "‚ö†Ô∏è  Note: Quality Gate status can be checked in SonarQube dashboard"
                        echo "   If Quality Gate FAILED, check:"
                        echo "   1. Fix the issues (currently 2 issues)"
                        echo "   2. Increase code coverage (currently 40.3%, target 80%)"
                        echo "   3. Review security hotspots"
                    }
                }
            }
        }
        
        stage('Build Docker Image') {
            steps {
                script {
                    echo "üê≥ Building NEW Docker image..."
                    echo "   Image: ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                    echo "   Tag: ${env.BUILD_NUMBER} (unique pour chaque build)"
                    echo "   Build avec --no-cache pour inclure toutes les d√©pendances (notamment Actuator)"
                    
                    sh """
                        # Build without cache to ensure Actuator dependencies are included
                        # Chaque build cr√©e une NOUVELLE image avec un tag unique (BUILD_NUMBER)
                        echo "üî® D√©marrage du build Docker..."
                        docker build --no-cache -t ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} .
                        
                        echo "üè∑Ô∏è  Tagging de l'image..."
                        docker tag ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest
                        
                        echo "‚úÖ Image Docker cr√©√©e avec succ√®s:"
                        docker images | grep ${env.DOCKER_IMAGE_NAME} | grep -E "${env.DOCKER_IMAGE_TAG}|latest" | head -2
                    """
                    
                    echo "‚úÖ Nouvelle image Docker cr√©√©e: ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                }
            }
        }
        
        stage('Push Docker Image') {
            steps {
                script {
                    echo "üì§ Pushing NEW Docker image to Docker Hub..."
                    echo "   Image tag: ${env.DOCKER_IMAGE_TAG} (Build #${env.BUILD_NUMBER})"
                    echo "   Image: ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                    
                    // Se connecter √† Docker Hub
                    echo "üîê Logging into Docker Hub..."
                    sh """
                        echo ${env.DOCKER_PASSWORD} | docker login -u ${env.DOCKER_USERNAME} --password-stdin
                    """
                    
                    // V√©rifier que l'image existe localement
                    echo "üîç V√©rification que la nouvelle image existe localement..."
                    sh """
                        echo "Images locales disponibles:"
                        docker images | grep ${env.DOCKER_IMAGE_NAME} | head -5
                        echo ""
                        echo "V√©rification de l'image tag ${env.DOCKER_IMAGE_TAG}..."
                        docker images | grep ${env.DOCKER_IMAGE_NAME} | grep ${env.DOCKER_IMAGE_TAG} || (echo "‚ùå Image tag ${env.DOCKER_IMAGE_TAG} not found locally" && exit 1)
                        echo "‚úÖ Image tag ${env.DOCKER_IMAGE_TAG} trouv√©e localement"
                    """
                    
                    // Pousser les images avec retry explicite
                    echo "üì§ Pushing new image to Docker Hub..."
                    
                    // Push tag BUILD_NUMBER avec retry
                    def pushSuccess1 = false
                    def retryCount1 = 0
                    def maxRetries1 = 3
                    while (retryCount1 < maxRetries1 && !pushSuccess1) {
                        try {
                            echo "üîÑ Pushing ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} (attempt ${retryCount1 + 1}/${maxRetries1})..."
                            sh "docker push ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                            pushSuccess1 = true
                            echo "‚úÖ Successfully pushed ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                        } catch (Exception e) {
                            retryCount1++
                            if (retryCount1 < maxRetries1) {
                                def waitTime = retryCount1 * 10
                                echo "‚ö†Ô∏è  Failed to push ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} (attempt ${retryCount1}/${maxRetries1}). Retrying in ${waitTime} seconds..."
                                sleep(waitTime)
                            } else {
                                echo "‚ùå Failed to push ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} after ${maxRetries1} attempts"
                                throw e
                            }
                        }
                    }
                    
                    // Push tag latest avec retry
                    def pushSuccess2 = false
                    def retryCount2 = 0
                    def maxRetries2 = 3
                    while (retryCount2 < maxRetries2 && !pushSuccess2) {
                        try {
                            echo "üîÑ Pushing ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest (attempt ${retryCount2 + 1}/${maxRetries2})..."
                            sh "docker push ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest"
                            pushSuccess2 = true
                            echo "‚úÖ Successfully pushed ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest"
                        } catch (Exception e) {
                            retryCount2++
                            if (retryCount2 < maxRetries2) {
                                def waitTime = retryCount2 * 10
                                echo "‚ö†Ô∏è  Failed to push ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest (attempt ${retryCount2}/${maxRetries2}). Retrying in ${waitTime} seconds..."
                                sleep(waitTime)
                            } else {
                                echo "‚ùå Failed to push ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest after ${maxRetries2} attempts"
                                throw e
                            }
                        }
                    }
                    
                    echo "‚úÖ All images pushed successfully to Docker Hub!"
                    echo ""
                    echo "üìä R√âSUM√â DU PUSH:"
                    echo "   ‚úÖ Nouvelle image pouss√©e: ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                    echo "   ‚úÖ Tag latest mis √† jour: ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:latest"
                    echo "   üîó Docker Hub: https://hub.docker.com/r/${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}"
                }
            }
        }
        
        stage('Create Kubernetes Namespace') {
            steps {
                script {
                    sh """
                        kubectl create namespace devops --dry-run=client -o yaml | kubectl apply -f -
                    """
                }
            }
        }
        
        stage('Deploy MySQL to Kubernetes') {
            steps {
                script {
                    sh """
                        kubectl apply -f k8s/mysql-secret.yaml
                        # Le PVC peut d√©j√† exister avec des param√®tres diff√©rents, on ignore l'erreur si c'est le cas
                        kubectl apply -f k8s/mysql-pvc.yaml || echo "PVC mysql-pvc exists with different spec, continuing..."
                        kubectl apply -f k8s/mysql-deployment.yaml
                        kubectl apply -f k8s/mysql-service.yaml
                    """
                }
            }
        }
        
        stage('Wait for MySQL to be Ready') {
            steps {
                script {
                    sh """
                        kubectl wait --for=condition=ready pod -l app=mysql -n devops --timeout=10s || true
                        echo "MySQL deployment completed!"
                    """
                }
            }
        }
        
        stage('Update App Image Tag') {
            steps {
                script {
                    sh """
                        # Supprimer les pods en erreur (ImagePullBackOff)
                        kubectl delete pod -n devops -l app=student-management --field-selector=status.phase!=Running --ignore-not-found=true || echo "No pods to delete"
                        
                        # Mettre √† jour l'image dans le deployment si il existe
                        kubectl set image deployment/student-management student-management=${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} -n devops --record || echo "Deployment not found, will be created in next stage"
                    """
                }
            }
        }
        
        stage('Deploy Application to Kubernetes') {
            steps {
                script {
                    sh """
                        kubectl apply -f k8s/app-configmap.yaml
                        kubectl apply -f k8s/app-secret.yaml
                        kubectl apply -f k8s/app-deployment.yaml
                        
                        # Mettre √† jour l'image avec le tag de build et forcer le pull
                        kubectl set image deployment/student-management student-management=${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG} -n devops --record || echo "Image update failed, using latest"
                        
                        # Forcer le pull de l'image en supprimant les pods existants
                        kubectl rollout restart deployment/student-management -n devops || echo "Rollout restart completed"
                        
                        kubectl apply -f k8s/app-service.yaml
                    """
                }
            }
        }
        
        stage('Wait for Application to be Ready') {
            steps {
                script {
                    sh """
                        kubectl wait --for=condition=ready pod -l app=student-management -n devops --timeout=300s || true
                        sleep 30
                        echo "Application deployment completed!"
                    """
                }
            }
        }
        
        stage('Expose Services and Test Application') {
            steps {
                script {
                    sh """
                        echo "=== Pods Status ==="
                        kubectl get pods -n devops
                        
                        echo "=== Services Status ==="
                        kubectl get services -n devops
                        
                        echo "=== Application Deployment Status ==="
                        kubectl get deployment student-management -n devops || echo "Deployment check completed"
                        
                        echo "=== Getting NodePort for Application ==="
                        NODEPORT=\$(kubectl get service student-management -n devops -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null || echo "30080")
                        # Obtenir l'IP du node directement via kubectl (plus fiable que minikube ip)
                        MINIKUBE_IP=\$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null || echo "192.168.49.2")
                        
                        echo "Application URL: http://\${MINIKUBE_IP}:\${NODEPORT}/student"
                        echo "Swagger UI: http://\${MINIKUBE_IP}:\${NODEPORT}/student/swagger-ui.html"
                        
                        echo "=== Testing Application ==="
                        sleep 15
                        kubectl exec -n devops \$(kubectl get pod -l app=student-management -n devops -o jsonpath='{.items[0].metadata.name}' 2>/dev/null | head -1) -- wget -qO- http://localhost:8089/student/swagger-ui.html | head -5 || echo "Health check via pod exec failed"
                    """
                }
            }
        }
        
        stage('Verify Code Quality on Pod') {
            steps {
                script {
                    sh """
                        echo "=== Checking Pod Logs for Code Quality ==="
                        kubectl logs -l app=student-management -n devops --tail=50 || echo "Logs check completed"
                        
                        echo "=== Pod Resource Usage ==="
                        kubectl top pods -n devops || echo "Metrics server not available"
                        
                        echo "=== Describing Pods ==="
                        kubectl describe pods -l app=student-management -n devops | head -50 || echo "Describe completed"
                    """
                }
            }
        }
        
        stage('Deploy Monitoring Stack (Prometheus & Grafana)') {
            steps {
                script {
                    // Cette √©tape est critique pour le monitoring - continuer m√™me en cas d'erreurs pr√©c√©dentes
                    try {
                    sh """
                        echo "========================================="
                        echo "üöÄ D√©ploiement du Monitoring Stack"
                        echo "========================================="
                        
                        # D√©tecter l'IP WSL pour la configuration Prometheus
                        WSL_IP=\$(ip addr show eth0 2>/dev/null | grep "inet " | awk '{print \$2}' | cut -d/ -f1 || echo "172.29.114.102")
                        echo "üì° IP WSL d√©tect√©e: \$WSL_IP"
                        
                        # Mettre √† jour la configuration Prometheus avec l'IP WSL
                        if [ -f k8s/prometheus-config.yaml ]; then
                            OLD_IP="172.29.114.102"
                            sed -i "s|\${OLD_IP}:8080|\${WSL_IP}:8080|g" k8s/prometheus-config.yaml 2>/dev/null || true
                            sed -i "s|\${OLD_IP}:9100|\${WSL_IP}:9100|g" k8s/prometheus-config.yaml 2>/dev/null || true
                            echo "‚úÖ Configuration Prometheus mise √† jour avec IP WSL: \$WSL_IP"
                        fi
                        
                        echo ""
                        echo "1Ô∏è‚É£  D√©ploiement de Node Exporter (m√©triques syst√®me)..."
                        kubectl apply -f k8s/node-exporter-deployment.yaml || echo "Node Exporter d√©j√† d√©ploy√©"
                        
                        # D√©marrer Node Exporter WSL si disponible
                        if systemctl is-available --quiet node_exporter.service 2>/dev/null; then
                            echo "   üîÑ D√©marrage de Node Exporter WSL..."
                            sudo systemctl start node_exporter 2>/dev/null || echo "   ‚ö†Ô∏è  Node Exporter WSL n√©cessite sudo"
                        fi
                        
                        echo ""
                        echo "2Ô∏è‚É£  D√©ploiement de Prometheus..."
                        kubectl apply -f k8s/prometheus-config.yaml
                        kubectl apply -f k8s/prometheus-deployment.yaml
                        kubectl apply -f k8s/prometheus-service.yaml
                        
                        echo ""
                        echo "3Ô∏è‚É£  D√©ploiement de Grafana..."
                        kubectl apply -f k8s/grafana-datasources.yaml
                        kubectl apply -f k8s/grafana-dashboards.yaml
                        kubectl apply -f k8s/grafana-dashboards-configmap.yaml
                        kubectl apply -f k8s/grafana-deployment.yaml
                        kubectl apply -f k8s/grafana-service.yaml
                        
                        echo ""
                        echo "4Ô∏è‚É£  Attente que les pods soient pr√™ts..."
                        sleep 15
                        kubectl wait --for=condition=ready pod -l app=prometheus -n devops --timeout=120s || echo "Prometheus en cours de d√©marrage..."
                        kubectl wait --for=condition=ready pod -l app=grafana -n devops --timeout=120s || echo "Grafana en cours de d√©marrage..."
                        kubectl wait --for=condition=ready pod -l app=node-exporter -n devops --timeout=60s || echo "Node Exporter en cours de d√©marrage..."
                        
                        echo ""
                        echo "‚úÖ Monitoring Stack d√©ploy√© !"
                        echo "========================================="
                    """
                    } catch (Exception e) {
                        echo "‚ö†Ô∏è  Erreur lors du d√©ploiement du Monitoring Stack: ${e.getMessage()}"
                        echo "   Le pipeline continue malgr√© cette erreur..."
                        // Ne pas faire √©chouer le pipeline √† cause du monitoring
                    }
                }
            }
        }
        
        stage('Verify Monitoring Stack (Prometheus & Grafana)') {
            steps {
                script {
                    sh """
                        echo "========================================="
                        echo "üìä V√©rification du Monitoring Stack"
                        echo "========================================="
                        
                        MINIKUBE_IP=\$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null || echo "192.168.49.2")
                        WSL_IP=\$(ip addr show eth0 2>/dev/null | grep "inet " | awk '{print \$2}' | cut -d/ -f1 || echo "172.29.114.102")
                        
                        echo ""
                        echo "1Ô∏è‚É£  V√©rification des pods Prometheus et Grafana..."
                        kubectl get pods -n devops -l 'app in (prometheus,grafana,node-exporter)' || echo "Monitoring pods check"
                        
                        echo ""
                        echo "2Ô∏è‚É£  V√©rification Prometheus..."
                        PROMETHEUS_STATUS=\$(curl -s -o /dev/null -w "%{http_code}" http://\${MINIKUBE_IP}:30909/api/v1/status/config || echo "000")
                        if [ "\$PROMETHEUS_STATUS" = "200" ]; then
                            echo "‚úÖ Prometheus est accessible (HTTP \$PROMETHEUS_STATUS)"
                        else
                            echo "‚ö†Ô∏è  Prometheus pourrait ne pas √™tre accessible (HTTP \$PROMETHEUS_STATUS)"
                        fi
                        
                        echo ""
                        echo "3Ô∏è‚É£  V√©rification Grafana..."
                        GRAFANA_STATUS=\$(curl -s -o /dev/null -w "%{http_code}" http://\${MINIKUBE_IP}:30300/api/health || echo "000")
                        if [ "\$GRAFANA_STATUS" = "200" ]; then
                            echo "‚úÖ Grafana est accessible (HTTP \$GRAFANA_STATUS)"
                        else
                            echo "‚ö†Ô∏è  Grafana pourrait ne pas √™tre accessible (HTTP \$GRAFANA_STATUS)"
                        fi
                        
                        echo ""
                        echo "4Ô∏è‚É£  V√©rification des targets Prometheus..."
                        TARGETS=\$(curl -s http://\${MINIKUBE_IP}:30909/api/v1/targets 2>/dev/null || echo "")
                        if [ -n "\$TARGETS" ]; then
                            echo "Targets trouv√©s:"
                            echo "\$TARGETS" | grep -o '"job":"[^"]*"' | sort | uniq || echo "   Parsing targets..."
                        else
                            echo "‚ö†Ô∏è  Impossible de r√©cup√©rer les targets Prometheus"
                        fi
                        
                        echo ""
                        echo "5Ô∏è‚É£  V√©rification Spring Boot Actuator..."
                        # S√©lectionner uniquement les pods en √©tat Running
                        APP_POD=\$(kubectl get pod -n devops -l app=student-management --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}' 2>/dev/null | head -1)
                        NODEPORT=\$(kubectl get service student-management -n devops -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null || echo "30080")
                        
                        if [ -n "\$APP_POD" ]; then
                            # V√©rifier que le pod est vraiment ready
                            POD_READY=\$(kubectl get pod \$APP_POD -n devops -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "False")
                            if [ "\$POD_READY" = "True" ]; then
                                # Tester Actuator depuis l'ext√©rieur (via NodePort) - plus fiable que exec
                                ACTUATOR_RESPONSE=\$(curl -s -o /dev/null -w "%{http_code}" http://\${MINIKUBE_IP}:\${NODEPORT}/student/actuator/prometheus 2>/dev/null || echo "000")
                                
                                if [ "\$ACTUATOR_RESPONSE" = "200" ]; then
                                    ACTUATOR_TEST=\$(curl -s http://\${MINIKUBE_IP}:\${NODEPORT}/student/actuator/prometheus 2>/dev/null | head -5 || echo "")
                                    if [ -n "\$ACTUATOR_TEST" ] && echo "\$ACTUATOR_TEST" | grep -q "# HELP"; then
                                        echo "‚úÖ Spring Boot Actuator fonctionne (pod: \$APP_POD)"
                                        echo "   M√©triques disponibles sur: http://\${MINIKUBE_IP}:\${NODEPORT}/student/actuator/prometheus"
                                        echo "   Exemple de m√©trique: \$(echo "\$ACTUATOR_TEST" | head -1)"
                                    else
                                        echo "‚ö†Ô∏è  Actuator r√©pond mais format inattendu (HTTP \$ACTUATOR_RESPONSE)"
                                        echo "   R√©ponse: \$(echo "\$ACTUATOR_TEST" | head -3)"
                                    fi
                                elif [ "\$ACTUATOR_RESPONSE" = "404" ]; then
                                    echo "‚ö†Ô∏è  Actuator endpoint non trouv√© (HTTP 404)"
                                    echo "   V√©rifiez que:"
                                    echo "   1. Le profile 'docker' est actif (v√©rifiez Dockerfile)"
                                    echo "   2. Les d√©pendances Actuator sont dans pom.xml"
                                    echo "   3. application-docker.properties contient la config Actuator"
                                    echo "   Logs du pod:"
                                    kubectl logs \$APP_POD -n devops --tail=20 | grep -i actuator || echo "   Aucun log Actuator trouv√©"
                                else
                                    echo "‚ö†Ô∏è  Actuator non accessible (HTTP \$ACTUATOR_RESPONSE)"
                                    echo "   Pod: \$APP_POD"
                                fi
                            else
                                echo "‚ö†Ô∏è  Pod \$APP_POD n'est pas en √©tat Ready (status: \$POD_READY)"
                                echo "   Liste des pods:"
                                kubectl get pods -n devops -l app=student-management | head -5
                            fi
                        else
                            echo "‚ö†Ô∏è  Aucun pod Running de l'application trouv√© pour tester Actuator"
                            echo "   Liste de tous les pods:"
                            kubectl get pods -n devops -l app=student-management || echo "Aucun pod trouv√©"
                        fi
                        
                        echo ""
                        echo "6Ô∏è‚É£  V√©rification Node Exporter..."
                        NODE_EXPORTER_POD=\$(kubectl get pod -n devops -l app=node-exporter -o jsonpath='{.items[0].metadata.name}' 2>/dev/null | head -1)
                        if [ -n "\$NODE_EXPORTER_POD" ]; then
                            NODE_METRICS=\$(kubectl exec -n devops \$NODE_EXPORTER_POD -- wget -qO- http://localhost:9100/metrics 2>/dev/null | grep -c "node_" || echo "0")
                            if [ "\$NODE_METRICS" -gt 0 ]; then
                                echo "‚úÖ Node Exporter fonctionne (\$NODE_METRICS m√©triques syst√®me trouv√©es)"
                            else
                                echo "‚ö†Ô∏è  Node Exporter pourrait ne pas fonctionner"
                            fi
                        else
                            echo "‚ö†Ô∏è  Node Exporter pod non trouv√©"
                        fi
                        
                        echo ""
                        echo "7Ô∏è‚É£  V√©rification Jenkins Metrics..."
                        JENKINS_TEST=\$(curl -s -o /dev/null -w "%{http_code}" http://\${WSL_IP}:8080/prometheus 2>/dev/null || echo "000")
                        if [ "\$JENKINS_TEST" = "200" ]; then
                            echo "‚úÖ Jenkins expose les m√©triques Prometheus (HTTP 200)"
                            echo "   Endpoint: http://\${WSL_IP}:8080/prometheus"
                            # Test rapide de r√©cup√©ration de m√©triques
                            JENKINS_METRICS_COUNT=\$(curl -s http://\${WSL_IP}:8080/prometheus 2>/dev/null | grep -c "^jenkins_" || echo "0")
                            if [ "\$JENKINS_METRICS_COUNT" -gt 0 ]; then
                                echo "   ‚úÖ \$JENKINS_METRICS_COUNT m√©triques Jenkins trouv√©es"
                            fi
                        elif [ "\$JENKINS_TEST" = "302" ]; then
                            # Tester avec le slash final (Jenkins redirige vers /prometheus/)
                            JENKINS_TEST_SLASH=\$(curl -s -o /dev/null -w "%{http_code}" http://\${WSL_IP}:8080/prometheus/ 2>/dev/null || echo "000")
                            if [ "\$JENKINS_TEST_SLASH" = "200" ]; then
                                echo "‚úÖ Jenkins expose les m√©triques Prometheus (HTTP 200 sur /prometheus/)"
                                echo "   Endpoint: http://\${WSL_IP}:8080/prometheus/"
                                JENKINS_METRICS_COUNT=\$(curl -s http://\${WSL_IP}:8080/prometheus/ 2>/dev/null | grep -c "^jenkins_" || echo "0")
                                if [ "\$JENKINS_METRICS_COUNT" -gt 0 ]; then
                                    echo "   ‚úÖ \$JENKINS_METRICS_COUNT m√©triques Jenkins trouv√©es"
                                fi
                            else
                                echo "‚ö†Ô∏è  Jenkins n√©cessite une authentification (HTTP \$JENKINS_TEST -> \$JENKINS_TEST_SLASH)"
                                echo "   Le plugin Prometheus est probablement install√© mais prot√©g√©"
                                echo "   Configurez Prometheus avec authentification ou exposez l'endpoint publiquement"
                                echo "   Endpoint: http://\${WSL_IP}:8080/prometheus/"
                            fi
                        elif [ "\$JENKINS_TEST" = "401" ] || [ "\$JENKINS_TEST" = "403" ]; then
                            echo "‚ö†Ô∏è  Jenkins n√©cessite une authentification (HTTP \$JENKINS_TEST)"
                            echo "   Le plugin Prometheus est probablement install√© mais prot√©g√©"
                            echo "   Configurez Prometheus avec authentification ou exposez l'endpoint publiquement"
                            echo "   Endpoint: http://\${WSL_IP}:8080/prometheus/"
                        else
                            echo "‚ö†Ô∏è  Jenkins ne semble pas exposer les m√©triques (HTTP \$JENKINS_TEST)"
                            echo "   V√©rifiez que:"
                            echo "   1. Le plugin 'Prometheus metrics plugin' est install√© dans Jenkins"
                            echo "   2. Jenkins est accessible depuis Prometheus sur: http://\${WSL_IP}:8080"
                            echo "   3. L'endpoint /prometheus est accessible"
                        fi
                        
                        echo ""
                        echo "========================================="
                        echo "üìä URLs du Monitoring"
                        echo "========================================="
                        echo "Prometheus: http://\${MINIKUBE_IP}:30909"
                        echo "   - Status: http://\${MINIKUBE_IP}:30909/api/v1/status/runtimeinfo"
                        echo "   - Targets: http://\${MINIKUBE_IP}:30909/targets"
                        echo "   - Graph: http://\${MINIKUBE_IP}:30909/graph"
                        echo ""
                        echo "Grafana: http://\${MINIKUBE_IP}:30300"
                        echo "   - Login: admin / admin"
                        echo "   - Dashboards: Automatiquement import√©s"
                        echo "     * Spring Boot Application Metrics"
                        echo "     * Jenkins Metrics"
                        echo "     * System Metrics (Node Exporter)"
                        echo ""
                        echo "Spring Actuator: http://\${MINIKUBE_IP}:30080/student/actuator/prometheus"
                        echo "Jenkins Metrics: http://\${WSL_IP}:8080/prometheus"
                        echo ""
                        echo "Pour acc√©der depuis Windows:"
                        echo "  Terminal 1: minikube service prometheus -n devops"
                        echo "  Terminal 2: minikube service grafana -n devops"
                        echo "========================================="
                    """
                }
            }
        }
    }
    
    post {
        always {
            cleanWs()
        }
        success {
            script {
                def NODEPORT = sh(script: "kubectl get service student-management -n devops -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null || echo '30080'", returnStdout: true).trim()
                def MINIKUBE_IP = sh(script: "kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type==\"InternalIP\")].address}' 2>/dev/null || echo '192.168.49.2'", returnStdout: true).trim()
                
                echo '=========================================='
                echo '‚úÖ Pipeline r√©ussi avec succ√®s!'
                echo '=========================================='
                echo "üìä SonarQube Dashboard: ${env.SONAR_HOST_URL}/dashboard?id=tn.esprit:student-management"
                echo "üê≥ Docker Image: ${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}:${env.DOCKER_IMAGE_TAG}"
                echo "üê≥ Docker Hub: https://hub.docker.com/r/${env.DOCKER_USERNAME}/${env.DOCKER_IMAGE_NAME}"
                echo "‚ò∏Ô∏è  Kubernetes Namespace: devops"
                echo "üåê Application URL: http://${MINIKUBE_IP}:${NODEPORT}/student"
                echo "üìö Swagger UI: http://${MINIKUBE_IP}:${NODEPORT}/student/swagger-ui.html"
                echo ""
                echo "üìä Monitoring Stack:"
                def WSL_IP = sh(script: "ip addr show eth0 2>/dev/null | grep 'inet ' | awk '{print \$2}' | cut -d/ -f1 || echo '172.29.114.102'", returnStdout: true).trim()
                echo "   üìà Prometheus: http://${MINIKUBE_IP}:30909"
                echo "   üìä Grafana: http://${MINIKUBE_IP}:30300 (admin/admin)"
                echo "   üîß Spring Actuator: http://${MINIKUBE_IP}:${NODEPORT}/student/actuator/prometheus"
                echo "   üèóÔ∏è  Jenkins Metrics: http://${WSL_IP}:8080/prometheus"
                echo '=========================================='
            }
        }
        failure {
            echo '‚ùå Pipeline a √©chou√©!'
            echo "V√©rifiez les logs ci-dessus pour identifier le probl√®me."
        }
        cleanup {
            sh 'docker logout || true'
        }
    }
}
